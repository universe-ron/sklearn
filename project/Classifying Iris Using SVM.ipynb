{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a765a2-c779-423b-b2b6-74af8309b41f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc40001-4619-47e0-907a-481d7934e98c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77879301-62fe-4784-85a1-eef6959246dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "def load_and_split_data() -> tuple:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        tuple: [X_train, X_test, y_train, y_test]\n",
    "    \"\"\"\n",
    "    # TODO:  Load iris data from sklearn.datasets and split the dataset into training and testing sets\n",
    "    iris = load_iris()\n",
    "    X, y = iris.data, iris.target\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def create_and_train_SVM(X_train: list, y_train: list) -> SVC:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        X_train: [features for training]\n",
    "        y_train: [labels for training]\n",
    "\n",
    "    Returns:\n",
    "        SVC: [Trained Support Vector Classifier model]\n",
    "    \"\"\"\n",
    "    # TODO: Create a Support Vector Classifier model and train the model on the training data\n",
    "    svm = SVC()\n",
    "    svm.fit(X_train, y_train)\n",
    "    return svm\n",
    "\n",
    "\n",
    "def make_predictions(model: SVC, X_test: list) -> list:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: [Trained Support Vector Classifier model]\n",
    "        X_test: [features for testing]\n",
    "\n",
    "    Returns:\n",
    "        list: [Predictions]\n",
    "    \"\"\"\n",
    "    # TODO: Make predictions using the trained model\n",
    "    predictions = model.predict(X_test)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and split the data\n",
    "    X_train, X_test, y_train, y_test = load_and_split_data()\n",
    "\n",
    "    # Create and train the SVM model\n",
    "    svm_model = create_and_train_SVM(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = make_predictions(svm_model, X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "    # Display classification report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a535bd04-8051-4935-b327-c039b14f71e3",
   "metadata": {},
   "source": [
    "This code loads the Iris dataset and split it into training and testing sets for machine learning purposes. Here's a breakdown of each part:\n",
    "\n",
    "Importing necessary libraries:\n",
    "sklearn.datasets is used to load datasets, including the Iris dataset.\n",
    "sklearn.model_selection provides utilities for splitting datasets into training and testing sets.\n",
    "sklearn.svm contains classes for Support Vector Machines (SVM), a type of machine learning algorithm.\n",
    "sklearn.metrics includes tools for evaluating the performance of models, such as accuracy and classification reports.\n",
    "Function Definition: A function named load_and_split_data is defined. This function does the following tasks:\n",
    "Loads the Iris dataset: load_iris() is a function provided by sklearn.datasets that loads the Iris flower dataset, which is a popular dataset for classification tasks. It contains measurements of 150 iris flowers from three different species.\n",
    "Data Separation: The dataset is separated into features (X) and target labels (y). In this case, X would be the 4-dimensional measurements of the iris flowers, and y would be the corresponding species labels (0, 1, or 2).\n",
    "Splitting the Data: train_test_split from sklearn.model_selection is used to split the data into training and testing subsets. The test_size=0.2 parameter means that 20% of the data will be used for testing, while the remaining 80% will be used for training. random_state=42 ensures reproducibility of the split; using the same seed (42 here) will yield the same split every time the code is run.\n",
    "Return Values: The function returns a tuple containing X_train, X_test, y_train, and y_test, which are the feature and target sets for both the training and testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b15cba-d64a-431c-8c2e-7b87b6fef15e",
   "metadata": {},
   "source": [
    "This function, create_and_train_SVM, is designed to instantiate a Support Vector Classifier (SVM) model using the sklearn.svm.SVC class and then train it on the provided training data. Here's a detailed explanation:\n",
    "\n",
    "Function Signature: The function takes two arguments:\n",
    "X_train: A list or array-like object containing the features (input variables) for the training dataset.\n",
    "y_train: A list or array-like object containing the corresponding labels (output variables) for the training dataset.\n",
    "Instantiating an SVM Model: Inside the function, SVC() is called without any parameters. This creates a default Support Vector Classifier model. The SVC class in scikit-learn offers various parameters to customize the model, such as kernel type, regularization, etc., but in this basic example, default values are used.\n",
    "Training the Model: The fit method of the svm object is called with X_train and y_train. This is where the actual training occursâ€”the model learns patterns from the features (X_train) associated with their respective class labels (y_train).\n",
    "Returning the Trained Model: After training, the function returns the trained SVC model. This model can then be used for making predictions on new, unseen data or for evaluating its performance using a test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d912883b-f9a3-48e5-97b4-e40441d7d271",
   "metadata": {},
   "source": [
    "The function make_predictions takes a trained SVM model and a set of test features as inputs, and it returns a list of predicted labels for the test data. Here's a breakdown:\n",
    "\n",
    "Function Arguments:\n",
    "model: This is an instance of the SVC class (Support Vector Classifier) that has already been trained on a dataset. It's assumed that the model knows how to classify new instances based on the patterns it learned during the training phase.\n",
    "X_test: A list or array-like object containing the features (input variables) for the test dataset. These are the unseen examples that the model will predict labels for.\n",
    "Making Predictions: Inside the function, the predict method of the model is invoked with X_test as its argument. The predict method applies the learned model to each instance in the test set to estimate their class labels. It doesn't require the true labels (y_test), only the input features.\n",
    "Returning Predictions: The function then returns these estimated labels as a list. Each element in the returned list corresponds to the predicted class label of the respective instance in the X_test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5f2564-551a-4f00-8f3b-77d186f07def",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
